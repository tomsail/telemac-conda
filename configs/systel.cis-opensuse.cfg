# _____                              _______________________________
# ____/ TELEMAC Project Definitions /______________________________/
#
#    space delimited list of active configurations
#
[Configurations]
configs:  susgfopenmpi
#
# _____          ___________________________________________________
# ____/ GENERAL /__________________________________________________/
[general]
modules:    system
#
cmd_lib:    ar cru <libname> <objs>
#
mods_all:   -I <config>
#
sfx_zip:    .gztar
sfx_lib:    .a
sfx_obj:    .o
sfx_mod:    .mod
sfx_exe:
#
val_root:   <root>/examples
val_rank:   all
# also possible val_rank:   <3 >7 6
cmd_obj_c: gcc -c <srcName> -o <objName>
#
# _____                            _________________________________
# ____/ OpenSUSE gfortran openMPI /________________________________/
[susgfopenmpi]
#
brief: parallel mode, using mpiexec directly (of the openMPI package).
       The only difference with the scalar versions (optimised) is the presence
       of the key mpi_cmdexec and the -DHAVE_MPI compilation directive.
       Of course, you also need the key par_cmdexec.
       Finally, note that this configuration also works whether
       processor is 0 or 1.
#
options: api static hermes_only
#
f2py_name: f2py3
pyd_fcompiler: gfortran
#
mpi_cmdexec:   /usr/lib64/mpi/gcc/openmpi/bin/mpiexec -wdir <wdir> -n <ncsize> --default-hostfile none <exename>
#
cmd_obj:    mpif90 -fPIC -c -cpp -g -DHAVE_AED2 -DHAVE_MPI -DHAVE_MUMPS -DHAVE_MED -fconvert=big-endian -frecord-marker=4 <mods> <incs> <f95name>
cmd_exe:    mpif90 -fPIC -fconvert=big-endian -frecord-marker=4 -v -lm -lz -o <exename> <objs> <libs>
#
incs_all:  -I /home/telemac/mumps/MUMPS_5.0.0/include/ -I /home/telemac/aed2/ -I /home/telemac/aed2/include/ -I /home/telemac/MED-3.3.1/include/
libs_all:  -L/home/telemac/mumps/MUMPS_5.0.0/lib -ldmumps -lmumps_common -lpord /home/telemac/mumps/SCALAPACK/libscalapack.a -L/home/telemac/mumps/BLAS-3.8.0 /home/telemac/mumps/BLAS-3.8.0/blas_LINUX.a /home/telemac/mumps/BLACS/LIB/blacs_MPI-LINUX-0.a /home/telemac/mumps/BLACS/LIB/blacsF77init_MPI-LINUX-0.a /home/telemac/mumps/BLACS/LIB/blacs_MPI-LINUX-0.a /home/telemac/metis-5.0.2/build/Linux-x86_64/libmetis/libmetis.a /home/telemac/aed2/libaed2.a -lm -L/home/telemac/MED-3.3.1/lib64/ -lmed -L/home/telemac/hdf5-1.8.14/lib64/ -lhdf5 -ldl -lstdc++ -lz -L$MPIHOME/lib64 -lmpi -lmpi_mpifh
#
# _____                    _________________________________________
# ____/ Other Definitions /________________________________________/
#
#
# ____/ OpenSUSE gfortran scalar /_________________________________/
[susgfortrans]
#
brief: scalar mode, Fortran optimisation 3.
   TELEMAC will work whether processor is 0 or 1
#
cmd_obj:    gfortran -c -cpp -O3 -fconvert=big-endian -frecord-marker=4 <mods> <incs> <f95name>
cmd_exe:    gfortran -fconvert=big-endian -frecord-marker=4 -v -lm -lz -o <exename> <objs> <libs>
#
# ____/ OpenSUSE gfortran scalar debug /___________________________/
[susgfortransdbg]
#
brief: scalar mode, Fortran debug mode.
   TELEMAC will work whether processor is 0 or 1
#
cmd_obj:    gfortran -c -g -fbounds-check -Wall -fbacktrace -finit-real=nan -fconvert=big-endian -frecord-marker=4 <mods> <incs> <f95name>
cmd_exe:    gfortran -fconvert=big-endian -frecord-marker=4 -v -lm -lz -o <exename> <objs> <libs>
#
#
# _____                     ________________________________________
# ____/ End of Definitions /_______________________________________/
#
